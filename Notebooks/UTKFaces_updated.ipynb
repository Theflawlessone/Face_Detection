{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "KCp3UtK1XTVl",
        "VLG5ONMJTaJc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os, tarfile, re, glob, random\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "q9syJa7NDaIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")"
      ],
      "metadata": {
        "id": "gWNp3V87GRDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "id": "30G6PQzhDdVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data extracting/loading (done)"
      ],
      "metadata": {
        "id": "KCp3UtK1XTVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "BASE_DIR = \".\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"UTKFace\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "FxC368ScDfnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n28CD0o7DtZC",
        "outputId": "05f5a244-6a83-4c0a-ccd6-94c9b929a8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet torch==2.2.2 torchvision==0.17.2 facenet-pytorch==2.6.0"
      ],
      "metadata": {
        "id": "y68VRXuBEo6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GDRIVE_ARCHIVE_BASE_PATH = \"/content/drive/MyDrive/UTK\"\n",
        "\n",
        "ARCHIVES = [\n",
        "    os.path.join(GDRIVE_ARCHIVE_BASE_PATH, \"part1.tar.gz\"),\n",
        "    os.path.join(GDRIVE_ARCHIVE_BASE_PATH, \"part2.tar.gz\"),\n",
        "    os.path.join(GDRIVE_ARCHIVE_BASE_PATH, \"part3.tar.gz\"),\n",
        "]\n",
        "\n",
        "def safe_extract(tar_path, extract_to):\n",
        "    with tarfile.open(tar_path, \"r:*\") as tar:\n",
        "        for member in tar.getmembers():\n",
        "            member_path = os.path.join(extract_to, member.name)\n",
        "            if not os.path.abspath(member_path).startswith(os.path.abspath(extract_to)):\n",
        "                raise Exception(f\"Unsafe path in {tar_path}: {member.name}\")\n",
        "        tar.extractall(extract_to)\n",
        "    print(f\"Extracted {os.path.basename(tar_path)}\")\n",
        "\n",
        "# Idempotent extraction loop\n",
        "for arc in ARCHIVES:\n",
        "    flag = os.path.join(DATA_DIR, f\".done_{os.path.basename(arc)}\")\n",
        "    if os.path.exists(flag):\n",
        "        print(f\"Already extracted: {os.path.basename(arc)}\")\n",
        "        continue\n",
        "    if not os.path.exists(arc):\n",
        "        print(f\"Missing archive: {arc}\")\n",
        "        continue\n",
        "    safe_extract(arc, DATA_DIR)\n",
        "    open(flag, \"w\").close()\n"
      ],
      "metadata": {
        "id": "FrrJZG3jDp-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbd7f74-52af-4b5f-e8ae-ae5fa53d38f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing archive: /content/drive/MyDrive/UTK/part1.tar.gz\n",
            "Missing archive: /content/drive/MyDrive/UTK/part2.tar.gz\n",
            "Missing archive: /content/drive/MyDrive/UTK/part3.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect & Parse Metadata\n",
        "image_paths = sorted(glob.glob(os.path.join(DATA_DIR, \"**\", \"*.jpg\"), recursive=True))\n",
        "print(f\"Found {len(image_paths)} images in total.\")\n",
        "\n",
        "def is_valid_image(path):\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        img.verify()\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def parse_label(path):\n",
        "    \"\"\"\n",
        "    Parse UTKFace filename: age_gender_race_*.jpg\n",
        "    gender: 0 = male, 1 = female\n",
        "    race: 0 = White, 1 = Black, 2 = Asian, 3 = Indian, 4 = Others\n",
        "    \"\"\"\n",
        "    name = os.path.basename(path)\n",
        "    match = re.match(r\"(\\d+)_(\\d+)_(\\d+)_\", name)\n",
        "    if not match:\n",
        "        return None, None, None\n",
        "    age = int(match.group(1))\n",
        "    gender = int(match.group(2))\n",
        "    race = int(match.group(3))\n",
        "    return age, gender, race\n",
        "\n",
        "records = []\n",
        "for p in image_paths:\n",
        "    if not is_valid_image(p):\n",
        "        continue\n",
        "    age, gender, race = parse_label(p)\n",
        "    if age is None:\n",
        "        continue\n",
        "    records.append([p, age, gender, race])\n",
        "\n",
        "df = pd.DataFrame(records, columns=[\"path\", \"age\", \"gender\", \"race\"])\n",
        "print(\"After cleaning:\", len(df))\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "jQwM3asUFjeN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b6b01241-9686-43ca-a008-510bf84c3b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images in total.\n",
            "After cleaning: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [path, age, gender, race]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92e6bc59-12f1-4465-9f8a-6b273280a253\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92e6bc59-12f1-4465-9f8a-6b273280a253')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92e6bc59-12f1-4465-9f8a-6b273280a253 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92e6bc59-12f1-4465-9f8a-6b273280a253');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchvision==0.15.2\n",
        "!pip install facenet-pytorch==2.5.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsVGbazj4XoH",
        "outputId": "a588fdea-82dd-422e-bb77-ad93b46d7ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting facenet-pytorch==2.5.3\n",
            "  Using cached facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch==2.5.3) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch==2.5.3) (2.32.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch==2.5.3) (0.17.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch==2.5.3) (10.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch==2.5.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch==2.5.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch==2.5.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->facenet-pytorch==2.5.3) (2025.11.12)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.12/dist-packages (from torchvision->facenet-pytorch==2.5.3) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2->torchvision->facenet-pytorch==2.5.3) (1.3.0)\n",
            "Using cached facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "Installing collected packages: facenet-pytorch\n",
            "  Attempting uninstall: facenet-pytorch\n",
            "    Found existing installation: facenet-pytorch 2.6.0\n",
            "    Uninstalling facenet-pytorch-2.6.0:\n",
            "      Successfully uninstalled facenet-pytorch-2.6.0\n",
            "Successfully installed facenet-pytorch-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# MTCNN face detector\n",
        "mtcnn = MTCNN(\n",
        "    image_size=224,   # final face size\n",
        "    margin=20,        # add a bit of context around face\n",
        "    post_process=False,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Directory where cropped faces will be stored\n",
        "CROPPED_DIR = \"/content/drive/MyDrive/UTK/cropped/UTKFace_cropped\"\n",
        "os.makedirs(CROPPED_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "0TA3UuLTGk2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec6d55d-94d9-43e4-d736-beb7a85d0356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cropped_dataframe(df, batch_size=32, mtcnn_input_size=256):\n",
        "    \"\"\"\n",
        "    Face cropping with MTCNN (single-image, robust).\n",
        "    - Uses existing global mtcnn and CROPPED_DIR.\n",
        "    - Reuses already-cropped files.\n",
        "    - Returns a new df with updated 'path' for successfully cropped images.\n",
        "    \"\"\"\n",
        "    old_to_new = {}\n",
        "    failed = []\n",
        "\n",
        "    paths = df[\"path\"].tolist()\n",
        "\n",
        "    for p in tqdm(paths, desc=\"Cropping faces (single-image MTCNN)\"):\n",
        "        filename = os.path.basename(p)\n",
        "        out_path = os.path.join(CROPPED_DIR, filename)\n",
        "\n",
        "        # If already cropped from a previous run, reuse it\n",
        "        if os.path.exists(out_path):\n",
        "            old_to_new[p] = out_path\n",
        "            continue\n",
        "\n",
        "        # Load original image\n",
        "        try:\n",
        "            img = Image.open(p).convert(\"RGB\")\n",
        "        except Exception:\n",
        "            failed.append(p)\n",
        "            continue\n",
        "\n",
        "        # Run MTCNN on a single image\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                face_tensor = mtcnn(img)\n",
        "        except Exception:\n",
        "            failed.append(p)\n",
        "            continue\n",
        "\n",
        "        # No face detected\n",
        "        if face_tensor is None:\n",
        "            failed.append(p)\n",
        "            continue\n",
        "\n",
        "        # Convert tensor -> uint8 PIL\n",
        "        face_tensor = face_tensor.clamp(0, 255)\n",
        "        np_img = face_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "        if np_img.dtype != \"uint8\":\n",
        "            np_img = np_img.astype(\"uint8\")\n",
        "\n",
        "        cropped_img = Image.fromarray(np_img)\n",
        "        cropped_img.save(out_path)\n",
        "\n",
        "        old_to_new[p] = out_path\n",
        "\n",
        "    print(f\"\\nTotal images: {len(paths)}\")\n",
        "    print(f\"Cropped / reused: {len(old_to_new)}\")\n",
        "    print(f\"Failed (no face or error): {len(failed)}\")\n",
        "\n",
        "    df_cropped = df[df[\"path\"].isin(old_to_new.keys())].copy()\n",
        "    df_cropped[\"path\"] = df_cropped[\"path\"].map(old_to_new)\n",
        "\n",
        "    return df_cropped, failed"
      ],
      "metadata": {
        "id": "h3J-r0haJF0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cropped, failed_paths = build_cropped_dataframe(df, batch_size=32)\n",
        "\n",
        "print(\"Original df:\", df.shape)\n",
        "print(\"Cropped df:\", df_cropped.shape)"
      ],
      "metadata": {
        "id": "baZRUdbEJIoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d8ee67-79df-47d6-fc2f-274a44cc6533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cropping faces (single-image MTCNN): 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total images: 0\n",
            "Cropped / reused: 0\n",
            "Failed (no face or error): 0\n",
            "Original df: (0, 4)\n",
            "Cropped df: (0, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len([f for f in os.listdir(CROPPED_DIR) if f.lower().endswith(\".jpg\")])"
      ],
      "metadata": {
        "id": "UBKlzMeCN2Sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3c2a09-1c5b-481e-c0e8-c6c45f789c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CROPPED_DIR = \"/content/drive/MyDrive/UTK/cropped/UTKFace_cropped\"\n",
        "image_paths = sorted(glob.glob(os.path.join(CROPPED_DIR, \"*.jpg\")))\n",
        "print(\"Found\", len(image_paths), \"cropped images\")\n",
        "\n",
        "def parse_label(name):\n",
        "    m = re.match(r\"(\\d+)_(\\d+)_(\\d+)_\", name)\n",
        "    if not m:\n",
        "        return None\n",
        "    age = int(m.group(1))\n",
        "    gender = int(m.group(2))\n",
        "    race = int(m.group(3))\n",
        "    return age, gender, race\n",
        "\n",
        "records = []\n",
        "for p in image_paths:\n",
        "    fname = os.path.basename(p)\n",
        "    parsed = parse_label(fname)\n",
        "    if parsed is None:\n",
        "        continue\n",
        "    age, gender, race = parsed\n",
        "    records.append({\"path\": p, \"age\": age, \"gender\": gender, \"race\": race})\n",
        "\n",
        "df_cropped = pd.DataFrame(records)\n",
        "print(df_cropped.shape)\n",
        "df_cropped.head()"
      ],
      "metadata": {
        "id": "j1wkYAavRVkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "932c281e-ee26-4f08-fd46-f2590f6a1627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 cropped images\n",
            "(0, 0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59dc4d37-9f98-4c43-bf33-a68f30e6768e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59dc4d37-9f98-4c43-bf33-a68f30e6768e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59dc4d37-9f98-4c43-bf33-a68f30e6768e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59dc4d37-9f98-4c43-bf33-a68f30e6768e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_cropped",
              "summary": "{\n  \"name\": \"df_cropped\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Age Buckets\n",
        "# 0–12: 0 (Child)\n",
        "# 13–19: 1 (Teenager)\n",
        "# 20–39: 2 (Young Adult)\n",
        "# 40–59: 3 (Middle-Aged)\n",
        "# 60+: 4 (Senior)\n",
        "\n",
        "NUM_AGE_GROUPS = 5\n",
        "NUM_GENDERS = 2\n",
        "NUM_RACES = 5\n",
        "\n",
        "def age_to_group(age):\n",
        "    if age <= 12:\n",
        "        return 0\n",
        "    elif age <= 19:\n",
        "        return 1\n",
        "    elif age <= 39:\n",
        "        return 2\n",
        "    elif age <= 59:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "df[\"age_group\"] = df[\"age\"].apply(age_to_group)"
      ],
      "metadata": {
        "id": "03Xo_572FpJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map readable gender, race, and age group strings\n",
        "gender_map = {0: \"Male\", 1: \"Female\"}\n",
        "race_map = {0: \"White\", 1: \"Black\", 2: \"Asian\", 3: \"Indian\", 4: \"Other\"}\n",
        "age_group_map = {\n",
        "    0: \"Child (0–12)\",\n",
        "    1: \"Teen (13–19)\",\n",
        "    2: \"Young Adult (20–39)\",\n",
        "    3: \"Middle-Aged (40–59)\",\n",
        "    4: \"Senior (60+)\"\n",
        "}\n",
        "\n",
        "df[\"gender_str\"] = df[\"gender\"].map(gender_map)\n",
        "df[\"race_str\"] = df[\"race\"].map(race_map)\n",
        "df[\"age_group_str\"] = df[\"age_group\"].map(age_group_map)"
      ],
      "metadata": {
        "id": "EBSJibqIF_UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Gender distribution:\")\n",
        "print(df[\"gender_str\"].value_counts())\n",
        "\n",
        "print(\"\\nRace distribution:\")\n",
        "print(df[\"race_str\"].value_counts())\n",
        "\n",
        "print(\"\\nAge group distribution:\")\n",
        "print(df[\"age_group_str\"].value_counts())"
      ],
      "metadata": {
        "id": "X7_Bc8UMFoCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9eaafb4-710e-465c-e822-56771a592043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender distribution:\n",
            "Series([], Name: count, dtype: int64)\n",
            "\n",
            "Race distribution:\n",
            "Series([], Name: count, dtype: int64)\n",
            "\n",
            "Age group distribution:\n",
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "sns.countplot(\n",
        "    data=df,\n",
        "    x=\"gender_str\",\n",
        "    order=df[\"gender_str\"].value_counts().index,\n",
        "    ax=axs[0]\n",
        ")\n",
        "axs[0].set_title(\"Gender Counts\")\n",
        "axs[0].set_xlabel(\"Gender\")\n",
        "axs[0].set_ylabel(\"Count\")\n",
        "\n",
        "sns.countplot(\n",
        "    data=df,\n",
        "    x=\"race_str\",\n",
        "    order=df[\"race_str\"].value_counts().index,\n",
        "    ax=axs[1]\n",
        ")\n",
        "axs[1].set_title(\"Race Counts\")\n",
        "axs[1].set_xlabel(\"Race\")\n",
        "axs[1].set_ylabel(\"Count\")\n",
        "axs[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "sns.countplot(\n",
        "    data=df,\n",
        "    x=\"age_group_str\",\n",
        "    order=df[\"age_group_str\"].value_counts().index,\n",
        "    ax=axs[2]\n",
        ")\n",
        "axs[2].set_title(\"Age Group Counts\")\n",
        "axs[2].set_xlabel(\"Age Group\")\n",
        "axs[2].set_ylabel(\"Count\")\n",
        "axs[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "31WFCbEHF300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "7746471f-7754-42b3-d6d1-e7be5c269930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratify by age_group for more balanced splits\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.3,\n",
        "    random_state=SEED,\n",
        "    stratify=df[\"age_group\"]\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=SEED,\n",
        "    stratify=temp_df[\"age_group\"]\n",
        ")\n",
        "\n",
        "print(len(train_df), len(val_df), len(test_df))"
      ],
      "metadata": {
        "id": "rTH0yBUtGAz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c43dc09e-b254-4b48-eab6-fc6abfd6bb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3175047363.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stratify by age_group for more balanced splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_df, temp_df = train_test_split(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, d in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
        "    print(f\"\\n{name.upper()} distribution:\")\n",
        "    print(\"Age groups:\\n\", d[\"age_group_str\"].value_counts())\n",
        "    print(\"Gender:\\n\", d[\"gender_str\"].value_counts())\n",
        "    print(\"Race:\\n\", d[\"race_str\"].value_counts())"
      ],
      "metadata": {
        "id": "vpnyA4eIGXpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save splits (this is done):\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VLG5ONMJTaJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PICKLE_DIR = \"/content/drive/MyDrive/UTK/UTKFace_pickles\"\n",
        "os.makedirs(PICKLE_DIR, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(PICKLE_DIR, \"df_cropped.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(df_cropped, f)\n",
        "\n",
        "with open(os.path.join(PICKLE_DIR, \"train_df.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(train_df, f)\n",
        "with open(os.path.join(PICKLE_DIR, \"val_df.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(val_df, f)\n",
        "with open(os.path.join(PICKLE_DIR, \"test_df.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(test_df, f)"
      ],
      "metadata": {
        "id": "PVxRR5b6Re7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pickles:"
      ],
      "metadata": {
        "id": "_CKdvYrWTdXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# START HERE\n",
        "import requests\n",
        "GITHUB_BASE = \"https://raw.githubusercontent.com/Theflawlessone/Face_Detection/main/pickle_files\"\n",
        "\n",
        "def load_pickle_from_github(filename):\n",
        "    url = f\"{GITHUB_BASE}/{filename}\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # catch 404 errors\n",
        "    return pickle.loads(response.content)"
      ],
      "metadata": {
        "id": "wv6ESgVIW1zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = load_pickle_from_github(\"train_df.pkl\")\n",
        "val_df   = load_pickle_from_github(\"val_df.pkl\")\n",
        "test_df  = load_pickle_from_github(\"test_df.pkl\")\n",
        "df_cropped = load_pickle_from_github(\"df_cropped.pkl\")"
      ],
      "metadata": {
        "id": "xW6Zd_aETe9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chacking Dataset columns and ensuring we can access the images"
      ],
      "metadata": {
        "id": "-D-Yt29Hzxps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_cropped.columns)"
      ],
      "metadata": {
        "id": "wP0ENXtFxnTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = df_cropped.sample(9, random_state=42)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, row in enumerate(sample.itertuples(), 1):\n",
        "    img = Image.open(row.path)\n",
        "    plt.subplot(3, 3, i)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Age: {row.age}, Gender: {row.gender}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5HYzunbezRQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age1_df = df_cropped[df_cropped[\"age\"] == 1]\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, row in enumerate(age1_df.tail(16).itertuples(), 1):  # show last 16\n",
        "    img = Image.open(row.path)\n",
        "    plt.subplot(4, 4, i)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    gender_label = \"Male\" if row.gender == 0 else \"Female\"\n",
        "    plt.title(f\"{gender_label}, Age 1\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zDJFKyKW4LiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary Statistics"
      ],
      "metadata": {
        "id": "ArxsSEYAyd-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_cropped.describe())"
      ],
      "metadata": {
        "id": "kquBNEr20Nnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Gender distribution:\")\n",
        "print(\"0 is male and 1 is female\")\n",
        "print(df_cropped[\"gender\"].value_counts())"
      ],
      "metadata": {
        "id": "Azv-Q3_b5vkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Male %:\", round(df_cropped[df_cropped.gender==0].shape[0] / len(df) * 100, 2))\n",
        "print(\"Female %:\", round(df_cropped[df_cropped.gender==1].shape[0] / len(df) * 100, 2))"
      ],
      "metadata": {
        "id": "fsd2hCbq2FF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Age distribution:\")\n",
        "print(df_cropped[\"age\"].value_counts())"
      ],
      "metadata": {
        "id": "ndrzcDBNyMF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AGE 26 perentage:\", round(df_cropped[df_cropped.age==26].shape[0] / len(df) * 100, 2))\n",
        "print(\"AGE 1 perentage:\", round(df_cropped[df_cropped.age==1].shape[0] / len(df) * 100, 2))\n",
        "print(\"AGE 28 perentage:\", round(df_cropped[df_cropped.age==28].shape[0] / len(df) * 100, 2))"
      ],
      "metadata": {
        "id": "34xonBm-2dij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cropped[df_cropped[\"age\"] == 1][\"gender\"].value_counts()"
      ],
      "metadata": {
        "id": "Yuv0m0yw5Ya9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs showing skewness/ unbalance"
      ],
      "metadata": {
        "id": "INPKRb-F09pZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(data=df_cropped, x=\"gender\")\n",
        "plt.title(\"Gender Distribution (0 = Male, 1 = Female)\")\n",
        "plt.xlabel(\"Gender\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hjBzAbWs079o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df_cropped[\"age\"], bins=30, kde=True)\n",
        "plt.title(\"Age Distribution in UTKFace Dataset\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8r_qxlWk0vAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,3))\n",
        "sns.boxplot(x=df_cropped[\"age\"])\n",
        "plt.title(\"Age Outlier Detection\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z9hde5_500zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "sns.boxplot(data=df_cropped, x=\"gender\", y=\"age\")\n",
        "plt.title(\"Age Distribution by Gender\")\n",
        "plt.xlabel(\"Gender (0=Male, 1=Female)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tdEVxuxd1jaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing the images and loading into an array"
      ],
      "metadata": {
        "id": "uXvlY0oh33tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224  # for ResNet\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])"
      ],
      "metadata": {
        "id": "pIZQf3FWYY1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLF"
      ],
      "metadata": {
        "id": "p_lg126SjyNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UTKFaceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Flexible dataset:\n",
        "    - mode = \"regression\": returns age (float)\n",
        "    - mode = \"age_group\": returns age_group (long)\n",
        "    - mode = \"multi\": returns both (plus gender, race)\n",
        "    \"\"\"\n",
        "    def __init__(self, df, transform=None, mode=\"age_group\"):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]\n",
        "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        age = torch.tensor(row[\"age\"], dtype=torch.float32)\n",
        "        age_group = torch.tensor(row[\"age_group\"], dtype=torch.long)\n",
        "        gender = torch.tensor(row[\"gender\"], dtype=torch.long)\n",
        "        race = torch.tensor(row[\"race\"], dtype=torch.long)\n",
        "\n",
        "        if self.mode == \"regression\":\n",
        "            return img, age, gender, race\n",
        "        elif self.mode == \"age_group\":\n",
        "            return img, age_group, gender, race\n",
        "        else:  # \"multi\"\n",
        "            return img, age, age_group, gender, race"
      ],
      "metadata": {
        "id": "d6HRPKK7Ybf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset objects from the pickle splits\n",
        "train_df = load_pickle_from_github(\"train_df.pkl\")\n",
        "val_df   = load_pickle_from_github(\"val_df.pkl\")\n",
        "test_df  = load_pickle_from_github(\"test_df.pkl\")"
      ],
      "metadata": {
        "id": "fZg8oEeQYn8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build datasets\n",
        "train_ds = UTKFaceDataset(train_df, transform=train_transform, mode=\"age_group\")   # change mode for regressions\n",
        "val_ds   = UTKFaceDataset(val_df,   transform=test_transform,  mode=\"age_group\")\n",
        "test_ds  = UTKFaceDataset(test_df,  transform=test_transform, mode=\"age_group\")"
      ],
      "metadata": {
        "id": "f3RWCc8TYqgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap them in loaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=(device.type == \"cuda\"),\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=(device.type == \"cuda\"),\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=(device.type == \"cuda\"),\n",
        ")"
      ],
      "metadata": {
        "id": "03MIKT0xYsze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "batch = next(iter(train_loader))\n",
        "print(len(batch))  # should be 4 for mode=\"age_group\": (img, age_group, gender, race)\n",
        "\n",
        "imgs, age_group, gender, race = batch\n",
        "print(imgs.shape)        # [B, 3, 224, 224]\n",
        "print(age_group.shape)   # [B]\n",
        "print(gender.shape)      # [B]\n",
        "print(race.shape)        # [B]"
      ],
      "metadata": {
        "id": "V7BxDPmqZEsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_AGE_GROUPS = 5  # 0–4\n",
        "\n",
        "class AgeGroupResNet18(nn.Module):\n",
        "    def __init__(self, num_age_groups=NUM_AGE_GROUPS):\n",
        "        super().__init__()\n",
        "        # Pretrained ResNet-18\n",
        "        self.base = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        in_feats = self.base.fc.in_features\n",
        "        # Replace final fc with our classifier\n",
        "        self.base.fc = nn.Linear(in_feats, num_age_groups)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base(x)  # logits [B, num_age_groups]"
      ],
      "metadata": {
        "id": "nJjiaOxgNFzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AgeGroupResNet18().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "5xaFv1b0cbN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, age_group, gender, race in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        age_group = age_group.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)           # [B, num_age_groups]\n",
        "        loss = criterion(logits, age_group)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        _, preds = logits.max(1)\n",
        "        correct += (preds == age_group).sum().item()\n",
        "        total += imgs.size(0)\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, age_group, gender, race in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        age_group = age_group.to(device)\n",
        "\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, age_group)\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        _, preds = logits.max(1)\n",
        "        correct += (preds == age_group).sum().item()\n",
        "        total += imgs.size(0)\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "yprH_LXqcV6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10  # you can bump this once it’s stable\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
        "    val_loss, val_acc = eval_one_epoch(model, val_loader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}:\")\n",
        "    print(f\"  Train - loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val   - loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_agegroup_resnet18.pt\")\n",
        "        print(\"  ↳ Saved new best model.\")"
      ],
      "metadata": {
        "id": "C-F79RXYcewd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_agegroup_resnet18.pt\", map_location=device))\n",
        "test_loss, test_acc = eval_one_epoch(model, test_loader, device)\n",
        "print(f\"Test - loss: {test_loss:.4f}, acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "aw1uks2Cchaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_by_group(model, loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    # overall\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # per gender and race\n",
        "    gender_correct = defaultdict(int)\n",
        "    gender_total = defaultdict(int)\n",
        "\n",
        "    race_correct = defaultdict(int)\n",
        "    race_total = defaultdict(int)\n",
        "\n",
        "    # optionally per age_group too\n",
        "    agegroup_correct = defaultdict(int)\n",
        "    agegroup_total = defaultdict(int)\n",
        "\n",
        "    for imgs, age_group, gender, race in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        age_group = age_group.to(device)\n",
        "\n",
        "        logits = model(imgs)\n",
        "        _, preds = logits.max(1)\n",
        "\n",
        "        batch_size = imgs.size(0)\n",
        "        total += batch_size\n",
        "        correct += (preds == age_group).sum().item()\n",
        "\n",
        "        # Move meta labels to CPU numpy\n",
        "        gender_np = gender.cpu().numpy()\n",
        "        race_np = race.cpu().numpy()\n",
        "        true_age_np = age_group.cpu().numpy()\n",
        "        pred_np = preds.cpu().numpy()\n",
        "\n",
        "        for g, r, t, p in zip(gender_np, race_np, true_age_np, pred_np):\n",
        "            # gender stats\n",
        "            gender_total[g] += 1\n",
        "            if p == t:\n",
        "                gender_correct[g] += 1\n",
        "\n",
        "            # race stats\n",
        "            race_total[r] += 1\n",
        "            if p == t:\n",
        "                race_correct[r] += 1\n",
        "\n",
        "            # age_group stats\n",
        "            agegroup_total[t] += 1\n",
        "            if p == t:\n",
        "                agegroup_correct[t] += 1\n",
        "\n",
        "    overall_acc = correct / total\n",
        "\n",
        "    gender_acc = {g: gender_correct[g] / gender_total[g] for g in gender_total}\n",
        "    race_acc   = {r: race_correct[r] / race_total[r] for r in race_total}\n",
        "    agegroup_acc = {a: agegroup_correct[a] / agegroup_total[a] for a in agegroup_total}\n",
        "\n",
        "    return overall_acc, gender_acc, race_acc, agegroup_acc\n"
      ],
      "metadata": {
        "id": "nKiiOM0bc0Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_by_group(model, loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # stats before mapping (keys are ints)\n",
        "    gender_correct = defaultdict(int)\n",
        "    gender_total   = defaultdict(int)\n",
        "\n",
        "    race_correct = defaultdict(int)\n",
        "    race_total   = defaultdict(int)\n",
        "\n",
        "    agegroup_correct = defaultdict(int)\n",
        "    agegroup_total   = defaultdict(int)\n",
        "\n",
        "    for imgs, age_group, gender, race in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        age_group = age_group.to(device)\n",
        "\n",
        "        logits = model(imgs)\n",
        "        _, preds = logits.max(1)\n",
        "\n",
        "        total += imgs.size(0)\n",
        "        correct += (preds == age_group).sum().item()\n",
        "\n",
        "        # move meta labels to CPU\n",
        "        g_np = gender.cpu().numpy()\n",
        "        r_np = race.cpu().numpy()\n",
        "        t_np = age_group.cpu().numpy()\n",
        "        p_np = preds.cpu().numpy()\n",
        "\n",
        "        for g, r, t, p in zip(g_np, r_np, t_np, p_np):\n",
        "            gender_total[g] += 1\n",
        "            race_total[r] += 1\n",
        "            agegroup_total[t] += 1\n",
        "\n",
        "            if p == t:\n",
        "                gender_correct[g] += 1\n",
        "                race_correct[r] += 1\n",
        "                agegroup_correct[t] += 1\n",
        "\n",
        "    # overall\n",
        "    overall_acc = correct / total\n",
        "\n",
        "    # map int keys -> strings\n",
        "    gender_acc = {\n",
        "        gender_map[g]: gender_correct[g] / gender_total[g]\n",
        "        for g in gender_total\n",
        "    }\n",
        "\n",
        "    race_acc = {\n",
        "        race_map[r]: race_correct[r] / race_total[r]\n",
        "        for r in race_total\n",
        "    }\n",
        "\n",
        "    agegroup_acc = {\n",
        "        age_group_map[a]: agegroup_correct[a] / agegroup_total[a]\n",
        "        for a in agegroup_total\n",
        "    }\n",
        "\n",
        "    return overall_acc, gender_acc, race_acc, agegroup_acc\n"
      ],
      "metadata": {
        "id": "UdZeIILwhg6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_acc, gender_acc, race_acc, agegroup_acc = eval_by_group(\n",
        "    model, test_loader, device\n",
        ")\n",
        "\n",
        "print(\"----Bias & Fairness Evaluation----\")\n",
        "print(\"Overall Accuracy:\", round(overall_acc, 4))\n",
        "print(\"\\nAccuracy by Gender:\")\n",
        "for k, v in gender_acc.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\nAccuracy by Race:\")\n",
        "for k, v in race_acc.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\nAccuracy by Age Group (True Labels):\")\n",
        "for k, v in agegroup_acc.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "cV1Dk6iohoT1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}